{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchattacks\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio, structural_similarity_index_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup CUDA Device\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Mobilenetv3Small\"\n",
    "version = \"v4\"\n",
    "training_name = \"ARD_Alpha=0.7_Temperature=5\"\n",
    "\n",
    "height = 224\n",
    "num_classes = 7\n",
    "epochs = 100\n",
    "lr = 0.00017\n",
    "lr_factor = 0.1\n",
    "lr_threshold = 6\n",
    "weight_decay = 0.0002\n",
    "batch_size = 32\n",
    "\n",
    "# Attack hyperparameters \n",
    "epsilon = 8.0 / 255\n",
    "alpha = 2.0 / 255\n",
    "steps = 10\n",
    "\n",
    "# Knowledge Distillation hyperparameters\n",
    "temp = 5.0\n",
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph writer initialize for data visualization\n",
    "\n",
    "writer = SummaryWriter(\"runs/trashbox/\" + f'{training_name}--{model_name}.{version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((height, height)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_preprocessing = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((height, height)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>> Preparing data...\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation dataset\n",
    "\n",
    "print('===>> Preparing data...')\n",
    "trash_train_dataset = torchvision.datasets.ImageFolder('dataset/trashbox/train', transform=preprocessing)\n",
    "trash_train_loader = torch.utils.data.DataLoader(dataset=trash_train_dataset, shuffle=True, batch_size=batch_size)\n",
    "trash_val_dataset = torchvision.datasets.ImageFolder('dataset/trashbox/val', transform=test_preprocessing)\n",
    "trash_val_loader = torch.utils.data.DataLoader(dataset=trash_val_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>> Setting up teacher model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('====>> Setting up teacher model...')\n",
    "\n",
    "# Initialize architecture with modified output features\n",
    "teacher_model = models.googlenet(weights=models.GoogLeNet_Weights.DEFAULT)\n",
    "infeatures = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(infeatures, num_classes, True)\n",
    "\n",
    "# Load saved weights \n",
    "checkpoint = torch.load('./best_trained_models/best_AT--Googlenet.v1_epoch98.pth')\n",
    "\n",
    "if 'module' in list(checkpoint['net'].keys())[0]:\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['net'].items()}\n",
    "    teacher_model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    teacher_model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>> Setting up student model...\n"
     ]
    }
   ],
   "source": [
    "# Setup student model \n",
    "\n",
    "print('====>> Setting up student model...')\n",
    "student_model = models.mobilenet_v3_small(weights=None)\n",
    "\n",
    "# for param in student_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "student_model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=576, out_features=1024, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1024, out_features=num_classes, bias=True)\n",
    ")\n",
    "\n",
    "# # Load saved weights \n",
    "# checkpoint = torch.load('./best_trained_models/best_NORMAL--Mobilenetv3Small.v1_epoch40.pth')\n",
    "\n",
    "# if 'module' in list(checkpoint['net'].keys())[0]:\n",
    "#     new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['net'].items()}\n",
    "#     student_model.load_state_dict(new_state_dict)\n",
    "# else:\n",
    "#     student_model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "student_model = student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adversarial attack for generating adversarial samples\n",
    "\n",
    "attack = torchattacks.TPGD(student_model, eps=epsilon, alpha=alpha, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loss functions\n",
    "\n",
    "XENT_loss = nn.CrossEntropyLoss()\n",
    "KL_loss = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loop\n",
    "\n",
    "def train(epoch, optimizer):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    adv_correct = 0\n",
    "    student_model.train()\n",
    "    total_ssim = 0\n",
    "    total_psnr = 0\n",
    "\n",
    "    iterator = tqdm(trash_train_loader, ncols=0, leave=False)\n",
    "    for i, (inputs, targets)in enumerate(iterator):\n",
    "        inputs, targets = inputs.to(device),targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        adv_image = attack(inputs, targets)\n",
    "\n",
    "        # Soft labels\n",
    "        teacher_output = teacher_model(inputs)\n",
    "        student_output = student_model(inputs)\n",
    "        adv_student_output = student_model(adv_image)\n",
    "        \n",
    "        # ARD loss function formula\n",
    "        loss =  alpha* temp* temp*KL_loss(F.log_softmax(adv_student_output/ temp, dim=1),F.softmax(teacher_output/ temp, dim=1))+(1.0- alpha)*XENT_loss(student_output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure loss\n",
    "        train_loss += loss.item()\n",
    "        iterator.set_description(str(loss.item()))      \n",
    "\n",
    "        # Get total \n",
    "        total += targets.size(0)\n",
    "\n",
    "        # SSIM and PSNR \n",
    "        total_psnr += peak_signal_noise_ratio(adv_image, inputs)\n",
    "        total_ssim += structural_similarity_index_measure(adv_image, inputs)\n",
    "        \n",
    "        # Measure clean and adversarial accuracy \n",
    "        _, predicted = student_output.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        _, adv_predicted = adv_student_output.max(1)\n",
    "        adv_correct += adv_predicted.eq(targets).sum().item()\n",
    "    \n",
    "    # SSIM and PSNR Average\n",
    "    avg_ssim = total_ssim / total\n",
    "    avg_psnr = total_psnr / total\n",
    "\n",
    "    writer.add_scalar(\"Average SSIM: \" + model_name, avg_ssim, epoch)\n",
    "    writer.add_scalar(\"Average PSNR: \" + model_name, avg_psnr, epoch)\n",
    "\n",
    "    training_loss = train_loss  / total\n",
    "    train_adv_accuracy = 100.0 * correct / total\n",
    "    adv_train_adv_accuracy = 100.0 * adv_correct / total\n",
    "    \n",
    "    print('\\nTotal adversarial train accuracy:', 100. * correct / total)\n",
    "    print('Total adversarial train loss:', train_loss)\n",
    "    \n",
    "    # Write graph over epoch\n",
    "    writer.add_scalar('Train loss: ' + model_name, training_loss, epoch)\n",
    "    writer.add_scalar('Train accuracy: ' + model_name, train_adv_accuracy, epoch)\n",
    "    writer.add_scalar('Adversarial Train accuracy: ' + model_name, adv_train_adv_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "best_loss = float(0)\n",
    "\n",
    "def test(epoch, optimizer):\n",
    "    global best_loss\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    student_model.eval()\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(trash_val_loader, ncols=0, leave=False)\n",
    "        for i, (inputs, targets) in enumerate(iterator):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                adv_images = attack(inputs, targets)\n",
    "            \n",
    "            # Output\n",
    "            natural_outputs = student_model(inputs)\n",
    "            adv_outputs = student_model(adv_images)\n",
    "\n",
    "            # Prediction\n",
    "            _, adv_predicted = adv_outputs.max(1)\n",
    "            _, natural_predicted = natural_outputs.max(1)\n",
    "            \n",
    "            # Correct top 1\n",
    "            benign_correct += natural_predicted.eq(targets).sum().item()\n",
    "            adv_correct += adv_predicted.eq(targets).sum().item()\n",
    "\n",
    "            iterator.set_description(str(adv_predicted.eq(targets).sum().item()/targets.size(0)))\n",
    "    \n",
    "    # Adversarial and Clean Accuracy \n",
    "    benign_val_accuracy = 100.0 * benign_correct / total\n",
    "    adv_val_accuracy = 100.0 * adv_correct / total \n",
    "    \n",
    "    # Logs\n",
    "    print('\\nTotal benign test accuarcy:', benign_val_accuracy)\n",
    "    print('Total adversarial test Accuarcy:', adv_val_accuracy)\n",
    "    \n",
    "    # Graph\n",
    "    writer.add_scalar(\"Natural test accuracy: \" + model_name, benign_val_accuracy, epoch)\n",
    "    writer.add_scalar(\"Adversarial test accuracy: \" + model_name, adv_val_accuracy, epoch)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    state = {\n",
    "        'epoch' : epoch,\n",
    "        'net': student_model.state_dict(),\n",
    "        'optim' : optimizer.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + f'{training_name}--{model_name}.{version}.pth')\n",
    "    if benign_val_accuracy > best_loss:\n",
    "        print(f'Model saved: f{benign_val_accuracy}')\n",
    "        torch.save(state, './trained_model/' + f'best_{training_name}_{model_name}_{version}_epoch{epoch}.pth')\n",
    "    print('Model Saved!')\n",
    "    return benign_val_accuracy, adv_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    learning_rate = lr\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate, weight_decay=0.0002)\n",
    "    model_path = f'./checkpoint/{training_name}--{model_name}.{version}.pth'\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=lr_threshold, factor=lr_factor)\n",
    "    if os.path.exists(model_path):\n",
    "        # Load the saved model and optimizer state\n",
    "        checkpoint = torch.load(model_path)\n",
    "        student_model.load_state_dict(checkpoint['net'])\n",
    "        optimizer.load_state_dict(checkpoint['optim'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"=> Loaded checkpoint '{model_path}' (epoch {start_epoch})\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        print(f\"=> No checkpoint found at '{model_path}'. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        train_loss = train(epoch, optimizer)\n",
    "        benign_val_accuracy , _ = test(epoch, optimizer)\n",
    "        scheduler.step(metrics=benign_val_accuracy, epoch=epoch)\n",
    "        scheduler.print_lr(True, student_model.parameters(), learning_rate, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> No checkpoint found at './checkpoint/ARD_Alpha=0.7_Temperature=5--Mobilenetv3Small.v4.pth'. Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/447 [00:00<?, ?it/s]c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\torch\\nn\\functional.py:2976: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "0.5968788266181946:   1% 3/447 [00:02<06:49,  1.08it/s]c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 31.556831710904124\n",
      "Total adversarial train loss: 256.04753854870796\n",
      "\n",
      "[ Test epoch: 0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:1064: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 34.306569343065696\n",
      "Total adversarial test Accuarcy: 21.224031443009544\n",
      "Model saved: f34.306569343065696\n",
      "Model Saved!\n",
      "Epoch 00000: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFD80> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 39.071363540864205\n",
      "Total adversarial train loss: 232.23380780220032\n",
      "\n",
      "[ Test epoch: 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 40.53902302077485\n",
      "Total adversarial test Accuarcy: 26.445816956765864\n",
      "Model saved: f40.53902302077485\n",
      "Model Saved!\n",
      "Epoch 00001: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFD80> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 41.80965053575181\n",
      "Total adversarial train loss: 223.2721776664257\n",
      "\n",
      "[ Test epoch: 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 41.661987647389104\n",
      "Total adversarial test Accuarcy: 29.084783829309377\n",
      "Model saved: f41.661987647389104\n",
      "Model Saved!\n",
      "Epoch 00002: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FF4C0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 43.448420757756146\n",
      "Total adversarial train loss: 215.19185507297516\n",
      "\n",
      "[ Test epoch: 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 45.87310499719259\n",
      "Total adversarial test Accuarcy: 32.6221224031443\n",
      "Model saved: f45.87310499719259\n",
      "Model Saved!\n",
      "Epoch 00003: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFAE0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 44.87008894180265\n",
      "Total adversarial train loss: 210.01050329208374\n",
      "\n",
      "[ Test epoch: 4 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 45.98540145985402\n",
      "Total adversarial test Accuarcy: 31.723750701852893\n",
      "Model saved: f45.98540145985402\n",
      "Model Saved!\n",
      "Epoch 00004: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFAE0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 46.36179004131942\n",
      "Total adversarial train loss: 203.4052678346634\n",
      "\n",
      "[ Test epoch: 5 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 49.3542953396968\n",
      "Total adversarial test Accuarcy: 35.03649635036496\n",
      "Model saved: f49.3542953396968\n",
      "Model Saved!\n",
      "Epoch 00005: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFD80> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 47.216191610056725\n",
      "Total adversarial train loss: 201.176798671484\n",
      "\n",
      "[ Test epoch: 6 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 47.95058955642897\n",
      "Total adversarial test Accuarcy: 37.675463222908476\n",
      "Model saved: f47.95058955642897\n",
      "Model Saved!\n",
      "Epoch 00006: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FF920> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 48.20365571818755\n",
      "Total adversarial train loss: 196.11781778931618\n",
      "\n",
      "[ Test epoch: 7 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 49.466591802358224\n",
      "Total adversarial test Accuarcy: 36.94553621560921\n",
      "Model saved: f49.466591802358224\n",
      "Model Saved!\n",
      "Epoch 00007: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FF920> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 48.16163596890539\n",
      "Total adversarial train loss: 191.96959222853184\n",
      "\n",
      "[ Test epoch: 8 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.25266704098821\n",
      "Total adversarial test Accuarcy: 37.113980909601345\n",
      "Model saved: f50.25266704098821\n",
      "Model Saved!\n",
      "Epoch 00008: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFA00> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.31017578261783\n",
      "Total adversarial train loss: 188.92543596029282\n",
      "\n",
      "[ Test epoch: 9 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 48.568220101066814\n",
      "Total adversarial test Accuarcy: 38.6299831555306\n",
      "Model saved: f48.568220101066814\n",
      "Model Saved!\n",
      "Epoch 00009: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFAE0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.01050493732054\n",
      "Total adversarial train loss: 187.40328082442284\n",
      "\n",
      "[ Test epoch: 10 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.44244806288602\n",
      "Total adversarial test Accuarcy: 37.7877596855699\n",
      "Model saved: f52.44244806288602\n",
      "Model Saved!\n",
      "Epoch 00010: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFAE0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.73884725821136\n",
      "Total adversarial train loss: 183.38335034251213\n",
      "\n",
      "[ Test epoch: 11 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.870297585626055\n",
      "Total adversarial test Accuarcy: 38.12464907355418\n",
      "Model saved: f50.870297585626055\n",
      "Model Saved!\n",
      "Epoch 00011: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FF4C0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.92093283843406\n",
      "Total adversarial train loss: 182.70768719911575\n",
      "\n",
      "[ Test epoch: 12 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.870297585626055\n",
      "Total adversarial test Accuarcy: 40.651319483436275\n",
      "Model saved: f50.870297585626055\n",
      "Model Saved!\n",
      "Epoch 00012: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FF4C0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.117025001750825\n",
      "Total adversarial train loss: 179.14206394553185\n",
      "\n",
      "[ Test epoch: 13 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.621560920830994\n",
      "Total adversarial test Accuarcy: 41.04435710275126\n",
      "Model saved: f53.621560920830994\n",
      "Model Saved!\n",
      "Epoch 00013: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFAE0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.25856152391624\n",
      "Total adversarial train loss: 176.93881058692932\n",
      "\n",
      "[ Test epoch: 14 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.45311622683885\n",
      "Total adversarial test Accuarcy: 40.7636159460977\n",
      "Model saved: f53.45311622683885\n",
      "Model Saved!\n",
      "Epoch 00014: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFD80> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.16051544225786\n",
      "Total adversarial train loss: 175.99961787462234\n",
      "\n",
      "[ Test epoch: 15 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.340819764177425\n",
      "Total adversarial test Accuarcy: 38.012352610892755\n",
      "Model saved: f53.340819764177425\n",
      "Model Saved!\n",
      "Epoch 00015: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFD80> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.87485118005463\n",
      "Total adversarial train loss: 174.10306030511856\n",
      "\n",
      "[ Test epoch: 16 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 54.01459854014598\n",
      "Total adversarial test Accuarcy: 41.15665356541269\n",
      "Model saved: f54.01459854014598\n",
      "Model Saved!\n",
      "Epoch 00016: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFA00> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 53.25302892359409\n",
      "Total adversarial train loss: 172.7299683690071\n",
      "\n",
      "[ Test epoch: 17 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.84615384615385\n",
      "Total adversarial test Accuarcy: 42.27961819202695\n",
      "Model saved: f53.84615384615385\n",
      "Model Saved!\n",
      "Epoch 00017: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFD80> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 53.239022340500036\n",
      "Total adversarial train loss: 171.4578753709793\n",
      "\n",
      "[ Test epoch: 18 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 55.75519371139809\n",
      "Total adversarial test Accuarcy: 39.58450308815272\n",
      "Model saved: f55.75519371139809\n",
      "Model Saved!\n",
      "Epoch 00018: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FF4C0> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 54.2895160725541\n",
      "Total adversarial train loss: 170.31835132837296\n",
      "\n",
      "[ Test epoch: 19 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.79000561482313\n",
      "Total adversarial test Accuarcy: 40.707467714766985\n",
      "Model saved: f53.79000561482313\n",
      "Model Saved!\n",
      "Epoch 00019: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFA00> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 54.12844036697248\n",
      "Total adversarial train loss: 170.14632646739483\n",
      "\n",
      "[ Test epoch: 20 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.06007860752386\n",
      "Total adversarial test Accuarcy: 40.14598540145985\n",
      "Model saved: f53.06007860752386\n",
      "Model Saved!\n",
      "Epoch 00020: adjusting learning rate of group <generator object Module.parameters at 0x000002A1888FFA00> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 54.57665102598221\n",
      "Total adversarial train loss: 166.44353500008583\n",
      "\n",
      "[ Test epoch: 21 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.34375:  52% 29/56 [00:30<00:29,  1.08s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisaimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
