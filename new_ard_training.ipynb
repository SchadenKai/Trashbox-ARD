{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim \n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchattacks\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio, structural_similarity_index_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup CUDA Device\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Mobilenetv3Small\"\n",
    "version = \"v4\"\n",
    "training_name = \"ARD\"\n",
    "\n",
    "height = 224\n",
    "num_classes = 7\n",
    "epochs = 50\n",
    "lr = 0.00017\n",
    "lr_factor = 0.1\n",
    "lr_threshold = 6\n",
    "weight_decay = 0.0002\n",
    "batch_size = 32\n",
    "\n",
    "# Attack hyperparameters \n",
    "epsilon = 8.0 / 255\n",
    "alpha = 2.0 / 255\n",
    "steps = 10\n",
    "\n",
    "# Knowledge Distillation hyperparameters\n",
    "temp = 20.0\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph writer initialize for data visualization\n",
    "\n",
    "writer = SummaryWriter(\"runs/trashbox/\" + f'{training_name}--{model_name}.{version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((height, height)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_preprocessing = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((height, height)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>> Preparing data...\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation dataset\n",
    "\n",
    "print('===>> Preparing data...')\n",
    "trash_train_dataset = torchvision.datasets.ImageFolder('dataset/trashbox/train', transform=preprocessing)\n",
    "trash_train_loader = torch.utils.data.DataLoader(dataset=trash_train_dataset, shuffle=True, batch_size=batch_size)\n",
    "trash_val_dataset = torchvision.datasets.ImageFolder('dataset/trashbox/val', transform=test_preprocessing)\n",
    "trash_val_loader = torch.utils.data.DataLoader(dataset=trash_val_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>> Setting up teacher model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('====>> Setting up teacher model...')\n",
    "\n",
    "# Initialize architecture with modified output features\n",
    "teacher_model = models.googlenet(weights=models.GoogLeNet_Weights.DEFAULT)\n",
    "infeatures = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(infeatures, num_classes, True)\n",
    "\n",
    "# Load saved weights \n",
    "checkpoint = torch.load('./best_trained_models/best_AT--Googlenet.v1_epoch98.pth')\n",
    "\n",
    "if 'module' in list(checkpoint['net'].keys())[0]:\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['net'].items()}\n",
    "    teacher_model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    teacher_model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>> Setting up student model...\n"
     ]
    }
   ],
   "source": [
    "# Setup student model \n",
    "\n",
    "print('====>> Setting up student model...')\n",
    "student_model = models.mobilenet_v3_small(weights=None)\n",
    "\n",
    "# for param in student_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "student_model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=576, out_features=1024, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1024, out_features=num_classes, bias=True)\n",
    ")\n",
    "\n",
    "# # Load saved weights \n",
    "# checkpoint = torch.load('./best_trained_models/best_NORMAL--Mobilenetv3Small.v1_epoch40.pth')\n",
    "\n",
    "# if 'module' in list(checkpoint['net'].keys())[0]:\n",
    "#     new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['net'].items()}\n",
    "#     student_model.load_state_dict(new_state_dict)\n",
    "# else:\n",
    "#     student_model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "student_model = student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adversarial attack for generating adversarial samples\n",
    "\n",
    "attack = torchattacks.TPGD(student_model, eps=epsilon, alpha=alpha, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loss functions\n",
    "\n",
    "XENT_loss = nn.CrossEntropyLoss()\n",
    "KL_loss = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loop\n",
    "\n",
    "def train(epoch, optimizer):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    adv_correct = 0\n",
    "    student_model.train()\n",
    "    total_ssim = 0\n",
    "    total_psnr = 0\n",
    "\n",
    "    iterator = tqdm(trash_train_loader, ncols=0, leave=False)\n",
    "    for i, (inputs, targets)in enumerate(iterator):\n",
    "        inputs, targets = inputs.to(device),targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        adv_image = attack(inputs, targets)\n",
    "\n",
    "        # Soft labels\n",
    "        teacher_output = teacher_model(inputs)\n",
    "        student_output = student_model(inputs)\n",
    "        adv_student_output = student_model(adv_image)\n",
    "        \n",
    "        # ARD loss function formula\n",
    "        loss =  alpha* temp* temp*KL_loss(F.log_softmax(adv_student_output/ temp, dim=1),F.softmax(teacher_output/ temp, dim=1))+(1.0- alpha)*XENT_loss(student_output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure loss\n",
    "        train_loss += loss.item()\n",
    "        iterator.set_description(str(loss.item()))      \n",
    "\n",
    "        # Get total \n",
    "        total += targets.size(0)\n",
    "\n",
    "        # SSIM and PSNR \n",
    "        total_psnr += peak_signal_noise_ratio(adv_image, inputs, reduction='sum')\n",
    "        total_ssim += structural_similarity_index_measure(adv_image, inputs, reduction='sum')\n",
    "        \n",
    "        # Measure clean and adversarial accuracy \n",
    "        _, predicted = student_output.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        _, adv_predicted = adv_student_output.max(1)\n",
    "        adv_correct += adv_predicted.eq(targets).sum().item()\n",
    "    \n",
    "    # SSIM and PSNR Average\n",
    "    avg_ssim = total_ssim / total\n",
    "    avg_psnr = total_psnr / total\n",
    "\n",
    "    writer.add_scalar(\"Average SSIM: \" + model_name, avg_ssim, epoch)\n",
    "    writer.add_scalar(\"Average PSNR: \" + model_name, avg_psnr, epoch)\n",
    "\n",
    "    training_loss = train_loss  / total\n",
    "    train_adv_accuracy = 100.0 * correct / total\n",
    "    adv_train_adv_accuracy = 100.0 * adv_correct / total\n",
    "    \n",
    "    print('\\nTotal adversarial train accuracy:', 100. * correct / total)\n",
    "    print('Total adversarial train loss:', train_loss)\n",
    "    \n",
    "    # Write graph over epoch\n",
    "    writer.add_scalar('Train loss: ' + model_name, training_loss, epoch)\n",
    "    writer.add_scalar('Train accuracy: ' + model_name, train_adv_accuracy, epoch)\n",
    "    writer.add_scalar('Adversarial Train accuracy: ' + model_name, adv_train_adv_accuracy, epoch)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "best_loss = float(0)\n",
    "\n",
    "def test(epoch, optimizer):\n",
    "    global best_loss\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    student_model.eval()\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(trash_val_loader, ncols=0, leave=False)\n",
    "        for i, (inputs, targets) in enumerate(iterator):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                adv_images = attack(inputs, targets)\n",
    "            \n",
    "            # Output\n",
    "            natural_outputs = student_model(inputs)\n",
    "            adv_outputs = student_model(adv_images)\n",
    "\n",
    "            # Prediction\n",
    "            _, adv_predicted = adv_outputs.max(1)\n",
    "            _, natural_predicted = natural_outputs.max(1)\n",
    "            \n",
    "            # Correct top 1\n",
    "            benign_correct += natural_predicted.eq(targets).sum().item()\n",
    "            adv_correct += adv_predicted.eq(targets).sum().item()\n",
    "\n",
    "            iterator.set_description(str(adv_predicted.eq(targets).sum().item()/targets.size(0)))\n",
    "    \n",
    "    # Adversarial and Clean Accuracy \n",
    "    benign_val_accuracy = 100.0 * benign_correct / total\n",
    "    adv_val_accuracy = 100.0 * adv_correct / total \n",
    "    \n",
    "    # Logs\n",
    "    print('\\nTotal benign test accuarcy:', benign_val_accuracy)\n",
    "    print('Total adversarial test Accuarcy:', adv_val_accuracy)\n",
    "    \n",
    "    # Graph\n",
    "    writer.add_scalar(\"Natural test accuracy: \" + model_name, benign_val_accuracy, epoch)\n",
    "    writer.add_scalar(\"Adversarial test accuracy: \" + model_name, adv_val_accuracy, epoch)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    state = {\n",
    "        'epoch' : epoch,\n",
    "        'net': student_model.state_dict(),\n",
    "        'optim' : optimizer.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + f'{training_name}--{model_name}.{version}.pth')\n",
    "    if benign_val_accuracy > best_loss:\n",
    "        print(f'Model saved: f{benign_val_accuracy}')\n",
    "        torch.save(state, './trained_model/' + f'best_{training_name}_{model_name}_{version}_epoch{epoch}.pth')\n",
    "    print('Model Saved!')\n",
    "    return benign_val_accuracy, adv_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    learning_rate = lr\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate, weight_decay=0.0002)\n",
    "    model_path = f'./checkpoint/{training_name}--{model_name}.{version}.pth'\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=lr_threshold, factor=lr_factor)\n",
    "    if os.path.exists(model_path):\n",
    "        # Load the saved model and optimizer state\n",
    "        checkpoint = torch.load(model_path)\n",
    "        student_model.load_state_dict(checkpoint['net'])\n",
    "        optimizer.load_state_dict(checkpoint['optim'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"=> Loaded checkpoint '{model_path}' (epoch {start_epoch})\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        print(f\"=> No checkpoint found at '{model_path}'. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        train_loss = train(epoch, optimizer)\n",
    "        benign_val_accuracy , _ = test(epoch, optimizer)\n",
    "        scheduler.step(metrics=train_loss, epoch=epoch)\n",
    "        scheduler.print_lr(True, student_model.parameters(), learning_rate, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded checkpoint './checkpoint/ARD--Mobilenetv3Small.v4.pth' (epoch 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/447 [00:00<?, ?it/s]c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\torch\\nn\\functional.py:2976: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "0.14409713447093964:   0% 0/447 [00:01<?, ?it/s]c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The `reduction=sum` will not have any effect when `dim` is None.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "0.08591531217098236:   2% 10/447 [00:11<08:16,  1.14s/it]c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.394215281182156\n",
      "Total adversarial train loss: 50.88530596345663\n",
      "\n",
      "[ Test epoch: 20 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\.conda\\envs\\thesisaimodel\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:1064: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 48.792813026389666\n",
      "Total adversarial test Accuarcy: 43.7956204379562\n",
      "Model saved: f48.792813026389666\n",
      "Model Saved!\n",
      "Epoch 00020: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.422228447370266\n",
      "Total adversarial train loss: 50.42973965406418\n",
      "\n",
      "[ Test epoch: 21 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 48.792813026389666\n",
      "Total adversarial test Accuarcy: 42.84110050533408\n",
      "Model saved: f48.792813026389666\n",
      "Model Saved!\n",
      "Epoch 00021: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.49226136284054\n",
      "Total adversarial train loss: 50.88567318022251\n",
      "\n",
      "[ Test epoch: 22 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.75800112296463\n",
      "Total adversarial test Accuarcy: 46.097697922515444\n",
      "Model saved: f50.75800112296463\n",
      "Model Saved!\n",
      "Epoch 00022: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.1981231178654\n",
      "Total adversarial train loss: 48.61687543988228\n",
      "\n",
      "[ Test epoch: 23 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.824817518248175\n",
      "Total adversarial test Accuarcy: 46.659180235822575\n",
      "Model saved: f51.824817518248175\n",
      "Model Saved!\n",
      "Epoch 00023: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.338188948805936\n",
      "Total adversarial train loss: 48.80772749334574\n",
      "\n",
      "[ Test epoch: 24 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 49.52274003368894\n",
      "Total adversarial test Accuarcy: 45.816956765861875\n",
      "Model saved: f49.52274003368894\n",
      "Model Saved!\n",
      "Epoch 00024: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.65333706842216\n",
      "Total adversarial train loss: 48.79383820295334\n",
      "\n",
      "[ Test epoch: 25 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.1965188096575\n",
      "Total adversarial test Accuarcy: 45.53621560920831\n",
      "Model saved: f50.1965188096575\n",
      "Model Saved!\n",
      "Epoch 00025: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 49.94047202185027\n",
      "Total adversarial train loss: 47.83514057844877\n",
      "\n",
      "[ Test epoch: 26 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.88096574957889\n",
      "Total adversarial test Accuarcy: 43.402582818641214\n",
      "Model saved: f51.88096574957889\n",
      "Model Saved!\n",
      "Epoch 00026: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.12255760207297\n",
      "Total adversarial train loss: 47.8135888017714\n",
      "\n",
      "[ Test epoch: 27 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.36496350364963\n",
      "Total adversarial test Accuarcy: 45.14317798989332\n",
      "Model saved: f50.36496350364963\n",
      "Model Saved!\n",
      "Epoch 00027: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.3606695146719\n",
      "Total adversarial train loss: 47.33225882798433\n",
      "\n",
      "[ Test epoch: 28 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.49859629421673\n",
      "Total adversarial test Accuarcy: 46.322290847838296\n",
      "Model saved: f52.49859629421673\n",
      "Model Saved!\n",
      "Epoch 00028: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.3606695146719\n",
      "Total adversarial train loss: 46.64226488023996\n",
      "\n",
      "[ Test epoch: 29 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.431779898933186\n",
      "Total adversarial test Accuarcy: 44.69399213924761\n",
      "Model saved: f51.431779898933186\n",
      "Model Saved!\n",
      "Epoch 00029: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.34666293157784\n",
      "Total adversarial train loss: 47.79323721677065\n",
      "\n",
      "[ Test epoch: 30 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.27400336889388\n",
      "Total adversarial test Accuarcy: 46.15384615384615\n",
      "Model saved: f52.27400336889388\n",
      "Model Saved!\n",
      "Epoch 00030: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.24308424959731\n",
      "Total adversarial train loss: 45.52433146908879\n",
      "\n",
      "[ Test epoch: 31 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.768669286917465\n",
      "Total adversarial test Accuarcy: 45.53621560920831\n",
      "Model saved: f51.768669286917465\n",
      "Model Saved!\n",
      "Epoch 00031: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.92093283843406\n",
      "Total adversarial train loss: 46.183323096483946\n",
      "\n",
      "[ Test epoch: 32 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.09489051094891\n",
      "Total adversarial test Accuarcy: 43.121841661987645\n",
      "Model saved: f51.09489051094891\n",
      "Model Saved!\n",
      "Epoch 00032: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.88591638069893\n",
      "Total adversarial train loss: 45.83940253406763\n",
      "\n",
      "[ Test epoch: 33 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.09489051094891\n",
      "Total adversarial test Accuarcy: 46.15384615384615\n",
      "Model saved: f51.09489051094891\n",
      "Model Saved!\n",
      "Epoch 00033: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 50.89992296379298\n",
      "Total adversarial train loss: 45.23188029974699\n",
      "\n",
      "[ Test epoch: 34 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.21785513756317\n",
      "Total adversarial test Accuarcy: 45.70466030320045\n",
      "Model saved: f52.21785513756317\n",
      "Model Saved!\n",
      "Epoch 00034: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.22907766650326\n",
      "Total adversarial train loss: 43.733008697628975\n",
      "\n",
      "[ Test epoch: 35 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.08422234699607\n",
      "Total adversarial test Accuarcy: 45.08702975856261\n",
      "Model saved: f50.08422234699607\n",
      "Model Saved!\n",
      "Epoch 00035: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.011975628545414\n",
      "Total adversarial train loss: 44.76273651048541\n",
      "\n",
      "[ Test epoch: 36 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.60022459292532\n",
      "Total adversarial test Accuarcy: 43.458731049971924\n",
      "Model saved: f51.60022459292532\n",
      "Model Saved!\n",
      "Epoch 00036: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.397156663631904\n",
      "Total adversarial train loss: 44.397863924503326\n",
      "\n",
      "[ Test epoch: 37 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.667040988208875\n",
      "Total adversarial test Accuarcy: 48.28747894441325\n",
      "Model saved: f52.667040988208875\n",
      "Model Saved!\n",
      "Epoch 00037: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.859373905735694\n",
      "Total adversarial train loss: 43.585524167865515\n",
      "\n",
      "[ Test epoch: 38 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 50.36496350364963\n",
      "Total adversarial test Accuarcy: 45.70466030320045\n",
      "Model saved: f50.36496350364963\n",
      "Model Saved!\n",
      "Epoch 00038: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.06947265214651\n",
      "Total adversarial train loss: 43.90507337078452\n",
      "\n",
      "[ Test epoch: 39 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.27400336889388\n",
      "Total adversarial test Accuarcy: 47.50140370578327\n",
      "Model saved: f52.27400336889388\n",
      "Model Saved!\n",
      "Epoch 00039: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.14650885916381\n",
      "Total adversarial train loss: 43.73718673363328\n",
      "\n",
      "[ Test epoch: 40 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.723189219539584\n",
      "Total adversarial test Accuarcy: 47.332959011791125\n",
      "Model saved: f52.723189219539584\n",
      "Model Saved!\n",
      "Epoch 00040: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.89439036347083\n",
      "Total adversarial train loss: 43.971238762140274\n",
      "\n",
      "[ Test epoch: 41 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.31948343627176\n",
      "Total adversarial test Accuarcy: 46.54688377316115\n",
      "Model saved: f51.31948343627176\n",
      "Model Saved!\n",
      "Epoch 00041: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.363610897121646\n",
      "Total adversarial train loss: 42.64749775826931\n",
      "\n",
      "[ Test epoch: 42 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.21785513756317\n",
      "Total adversarial test Accuarcy: 47.78214486243683\n",
      "Model saved: f52.21785513756317\n",
      "Model Saved!\n",
      "Epoch 00042: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.28657469010435\n",
      "Total adversarial train loss: 43.335441552102566\n",
      "\n",
      "[ Test epoch: 43 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.9371139809096\n",
      "Total adversarial test Accuarcy: 46.88377316114543\n",
      "Model saved: f51.9371139809096\n",
      "Model Saved!\n",
      "Epoch 00043: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.922403529658936\n",
      "Total adversarial train loss: 42.46371237188578\n",
      "\n",
      "[ Test epoch: 44 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.04941044357103\n",
      "Total adversarial test Accuarcy: 46.771476698484\n",
      "Model saved: f52.04941044357103\n",
      "Model Saved!\n",
      "Epoch 00044: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 51.60725541004272\n",
      "Total adversarial train loss: 42.95815173536539\n",
      "\n",
      "[ Test epoch: 45 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.03874227961819\n",
      "Total adversarial test Accuarcy: 45.816956765861875\n",
      "Model saved: f51.03874227961819\n",
      "Model Saved!\n",
      "Epoch 00045: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE3680> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.50367672806219\n",
      "Total adversarial train loss: 42.94339594617486\n",
      "\n",
      "[ Test epoch: 46 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 53.284671532846716\n",
      "Total adversarial test Accuarcy: 48.11903425042111\n",
      "Model saved: f53.284671532846716\n",
      "Model Saved!\n",
      "Epoch 00046: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.881854471601656\n",
      "Total adversarial train loss: 42.0409861728549\n",
      "\n",
      "[ Test epoch: 47 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 51.54407636159461\n",
      "Total adversarial test Accuarcy: 48.231330713082535\n",
      "Model saved: f51.54407636159461\n",
      "Model Saved!\n",
      "Epoch 00047: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.50367672806219\n",
      "Total adversarial train loss: 41.88702003657818\n",
      "\n",
      "[ Test epoch: 48 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 52.61089275687816\n",
      "Total adversarial test Accuarcy: 46.322290847838296\n",
      "Model saved: f52.61089275687816\n",
      "Model Saved!\n",
      "Epoch 00048: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 52.804818264584355\n",
      "Total adversarial train loss: 41.2615753673017\n",
      "\n",
      "[ Test epoch: 49 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 54.40763615946098\n",
      "Total adversarial test Accuarcy: 48.231330713082535\n",
      "Model saved: f54.40763615946098\n",
      "Model Saved!\n",
      "Epoch 00049: adjusting learning rate of group <generator object Module.parameters at 0x000002A18BAE0F20> to 1.7000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisaimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
