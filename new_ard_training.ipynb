{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim \n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchattacks\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio, structural_similarity_index_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup CUDA Device\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Mobilenetv3Small\"\n",
    "version = \"v1\"\n",
    "training_name = \"ARD_0.7_Temp=5\"\n",
    "\n",
    "height = 224\n",
    "num_classes = 7\n",
    "epochs = 100\n",
    "lr = 0.0001\n",
    "lr_factor = 0.1\n",
    "lr_threshold = 6\n",
    "weight_decay = 0.0002\n",
    "batch_size = 32\n",
    "\n",
    "# Attack hyperparameters \n",
    "epsilon = 8.0 / 255\n",
    "alpha = 2.0 / 255\n",
    "steps = 4\n",
    "\n",
    "# Knowledge Distillation hyperparameters\n",
    "temp = 5.0\n",
    "alpha = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph writer initialize for data visualization\n",
    "\n",
    "writer = SummaryWriter(\"runs/trashbox/\" + f'{training_name}--{model_name}.{version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((height, height)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_preprocessing = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((height, height)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>> Preparing data...\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation dataset\n",
    "\n",
    "print('===>> Preparing data...')\n",
    "trash_train_dataset = torchvision.datasets.ImageFolder('dataset/trashbox/train', transform=preprocessing)\n",
    "trash_train_loader = torch.utils.data.DataLoader(dataset=trash_train_dataset, shuffle=True, batch_size=batch_size)\n",
    "trash_val_dataset = torchvision.datasets.ImageFolder('dataset/trashbox/val', transform=test_preprocessing)\n",
    "trash_val_loader = torch.utils.data.DataLoader(dataset=trash_val_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>> Setting up teacher model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('====>> Setting up teacher model...')\n",
    "\n",
    "# Initialize architecture with modified output features\n",
    "teacher_model = models.googlenet(weights=models.GoogLeNet_Weights.DEFAULT)\n",
    "infeatures = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(infeatures, num_classes, True)\n",
    "\n",
    "# Load saved weights \n",
    "checkpoint = torch.load('./best_trained_models/best_AT--Googlenet.v1_epoch98.pth')\n",
    "\n",
    "if 'module' in list(checkpoint['net'].keys())[0]:\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['net'].items()}\n",
    "    teacher_model.load_state_dict(new_state_dict)\n",
    "else:\n",
    "    teacher_model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====>> Setting up student model...\n"
     ]
    }
   ],
   "source": [
    "# Setup student model \n",
    "\n",
    "print('====>> Setting up student model...')\n",
    "student_model = models.mobilenet_v3_small(weights=None)\n",
    "\n",
    "# for param in student_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "student_model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=576, out_features=1024, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1024, out_features=num_classes, bias=True)\n",
    ")\n",
    "\n",
    "# Load saved weights \n",
    "# checkpoint = torch.load('./best_trained_models/best_NORMAL--Mobilenetv3Small.v1_epoch40.pth')\n",
    "\n",
    "# if 'module' in list(checkpoint['net'].keys())[0]:\n",
    "#     new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint['net'].items()}\n",
    "#     student_model.load_state_dict(new_state_dict)\n",
    "# else:\n",
    "#     student_model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "student_model = student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adversarial attack for generating adversarial samples\n",
    "\n",
    "attack = torchattacks.PGD(student_model, eps=epsilon, alpha=alpha, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loss functions\n",
    "\n",
    "XENT_loss = nn.CrossEntropyLoss()\n",
    "KL_loss = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Loop\n",
    "\n",
    "def train(epoch, optimizer):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    adv_correct = 0\n",
    "    student_model.train()\n",
    "    total_ssim = 0\n",
    "    total_psnr = 0\n",
    "\n",
    "    iterator = tqdm(trash_train_loader, ncols=0, leave=False)\n",
    "    for i, (inputs, targets)in enumerate(iterator):\n",
    "        inputs, targets = inputs.to(device),targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        adv_image = attack(inputs, targets)\n",
    "\n",
    "        # Soft labels\n",
    "        teacher_output = teacher_model(inputs)\n",
    "        student_output = student_model(inputs)\n",
    "        adv_student_output = student_model(adv_image)\n",
    "        \n",
    "        # ARD loss function formula\n",
    "        loss =  alpha* temp* temp*KL_loss(F.log_softmax(adv_student_output/ temp, dim=1),F.softmax(teacher_output/ temp, dim=1))+(1.0- alpha)*XENT_loss(student_output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure loss\n",
    "        train_loss += loss.item()\n",
    "        iterator.set_description(str(loss.item()))      \n",
    "\n",
    "        # Get total \n",
    "        total += targets.size(0)\n",
    "\n",
    "        # SSIM and PSNR \n",
    "        total_psnr += peak_signal_noise_ratio(adv_image, inputs, reduction='sum')\n",
    "        total_ssim += structural_similarity_index_measure(adv_image, inputs, reduction='sum')\n",
    "        \n",
    "        # Measure clean and adversarial accuracy \n",
    "        _, predicted = student_output.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        _, adv_predicted = adv_student_output.max(1)\n",
    "        adv_correct += adv_predicted.eq(targets).sum().item()\n",
    "    \n",
    "    # SSIM and PSNR Average\n",
    "    avg_ssim = total_ssim / total\n",
    "    avg_psnr = total_psnr / total\n",
    "\n",
    "    writer.add_scalar(\"Average SSIM: \" + model_name, avg_ssim, epoch)\n",
    "    writer.add_scalar(\"Average PSNR: \" + model_name, avg_psnr, epoch)\n",
    "\n",
    "    training_loss = train_loss  / total\n",
    "    train_adv_accuracy = 100.0 * correct / total\n",
    "    adv_train_adv_accuracy = 100.0 * adv_correct / total\n",
    "    \n",
    "    print('\\nTotal adversarial train accuracy:', 100. * correct / total)\n",
    "    print('Total adversarial train loss:', train_loss)\n",
    "    \n",
    "    # Write graph over epoch\n",
    "    writer.add_scalar('Train loss: ' + model_name, training_loss, epoch)\n",
    "    writer.add_scalar('Train accuracy: ' + model_name, train_adv_accuracy, epoch)\n",
    "    writer.add_scalar('Adversarial Train accuracy: ' + model_name, adv_train_adv_accuracy, epoch)\n",
    "\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "best_acc = float(0)\n",
    "\n",
    "def test(epoch, optimizer):\n",
    "    global best_acc\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    student_model.eval()\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm(trash_val_loader, ncols=0, leave=False)\n",
    "        for i, (inputs, targets) in enumerate(iterator):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "\n",
    "            with torch.enable_grad():\n",
    "                adv_images = attack(inputs, targets)\n",
    "            \n",
    "            # Output\n",
    "            natural_outputs = student_model(inputs)\n",
    "            adv_outputs = student_model(adv_images)\n",
    "\n",
    "            # Prediction\n",
    "            _, adv_predicted = adv_outputs.max(1)\n",
    "            _, natural_predicted = natural_outputs.max(1)\n",
    "            \n",
    "            # Correct top 1\n",
    "            benign_correct += natural_predicted.eq(targets).sum().item()\n",
    "            adv_correct += adv_predicted.eq(targets).sum().item()\n",
    "\n",
    "            iterator.set_description(str(adv_predicted.eq(targets).sum().item()/targets.size(0)))\n",
    "    \n",
    "    # Adversarial and Clean Accuracy \n",
    "    benign_val_accuracy = 100.0 * benign_correct / total\n",
    "    adv_val_accuracy = 100.0 * adv_correct / total \n",
    "    \n",
    "    # Logs\n",
    "    print('\\nTotal benign test accuarcy:', benign_val_accuracy)\n",
    "    print('Total adversarial test Accuarcy:', adv_val_accuracy)\n",
    "    \n",
    "    # Graph\n",
    "    writer.add_scalar(\"Natural test accuracy: \" + model_name, benign_val_accuracy, epoch)\n",
    "    writer.add_scalar(\"Adversarial test accuracy: \" + model_name, adv_val_accuracy, epoch)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    state = {\n",
    "        'epoch' : epoch,\n",
    "        'net': student_model.state_dict(),\n",
    "        'optim' : optimizer.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + f'{training_name}--{model_name}.{version}.pth')\n",
    "    if benign_val_accuracy > best_acc:\n",
    "        print(f'Model saved: f{benign_val_accuracy}')\n",
    "        best_acc = benign_val_accuracy\n",
    "        torch.save(state, './trained_model/' + f'best_{training_name}_{model_name}_{version}_epoch{epoch}.pth')\n",
    "    print('Model Saved!')\n",
    "    return benign_val_accuracy, adv_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    learning_rate = lr\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate, weight_decay=0.0002)\n",
    "    model_path = f'./checkpoint/{training_name}--{model_name}.{version}.pth'\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=lr_threshold, factor=lr_factor)\n",
    "    if os.path.exists(model_path):\n",
    "        # Load the saved model and optimizer state\n",
    "        checkpoint = torch.load(model_path)\n",
    "        student_model.load_state_dict(checkpoint['net'])\n",
    "        optimizer.load_state_dict(checkpoint['optim'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"=> Loaded checkpoint '{model_path}' (epoch {start_epoch})\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        print(f\"=> No checkpoint found at '{model_path}'. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        train_loss = train(epoch, optimizer)\n",
    "        benign_val_accuracy , _ = test(epoch, optimizer)\n",
    "        scheduler.step(metrics=train_loss, epoch=epoch)\n",
    "        scheduler.print_lr(True, student_model.parameters(), learning_rate, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded checkpoint './checkpoint/ARD_0.7_Temp=5--Mobilenetv3Small.v1.pth' (epoch 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 65.06057847188178\n",
      "Total adversarial train loss: 173.72823160886765\n",
      "\n",
      "[ Test epoch: 75 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.292532285233015\n",
      "Total adversarial test Accuarcy: 32.45367770915216\n",
      "Model saved: f59.292532285233015\n",
      "Model Saved!\n",
      "Epoch 00075: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 64.46529869038449\n",
      "Total adversarial train loss: 173.86176976561546\n",
      "\n",
      "[ Test epoch: 76 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.47164514317799\n",
      "Total adversarial test Accuarcy: 36.10331274564851\n",
      "Model saved: f60.47164514317799\n",
      "Model Saved!\n",
      "Epoch 00076: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 64.83647314237692\n",
      "Total adversarial train loss: 172.60813653469086\n",
      "\n",
      "[ Test epoch: 77 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.74171813587872\n",
      "Total adversarial test Accuarcy: 34.7557551937114\n",
      "Model Saved!\n",
      "Epoch 00077: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 65.34071013376287\n",
      "Total adversarial train loss: 172.51842385530472\n",
      "\n",
      "[ Test epoch: 78 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 58.394160583941606\n",
      "Total adversarial test Accuarcy: 34.19427288040427\n",
      "Model Saved!\n",
      "Epoch 00078: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 65.64885496183206\n",
      "Total adversarial train loss: 169.20270401239395\n",
      "\n",
      "[ Test epoch: 79 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.629421673217294\n",
      "Total adversarial test Accuarcy: 35.09264458169568\n",
      "Model Saved!\n",
      "Epoch 00079: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 65.64185167028504\n",
      "Total adversarial train loss: 170.5258210003376\n",
      "\n",
      "[ Test epoch: 80 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 61.706906232453676\n",
      "Total adversarial test Accuarcy: 37.057832678270636\n",
      "Model saved: f61.706906232453676\n",
      "Model Saved!\n",
      "Epoch 00080: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133BC0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 65.13761467889908\n",
      "Total adversarial train loss: 169.595505297184\n",
      "\n",
      "[ Test epoch: 81 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.86468276249298\n",
      "Total adversarial test Accuarcy: 35.204941044357106\n",
      "Model Saved!\n",
      "Epoch 00081: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133140> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.24413474332937\n",
      "Total adversarial train loss: 168.61082424223423\n",
      "\n",
      "[ Test epoch: 82 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.078607523863\n",
      "Total adversarial test Accuarcy: 33.29590117911286\n",
      "Model Saved!\n",
      "Epoch 00082: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133140> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.49625323902234\n",
      "Total adversarial train loss: 166.79673896729946\n",
      "\n",
      "[ Test epoch: 83 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 61.48231330713082\n",
      "Total adversarial test Accuarcy: 34.86805165637283\n",
      "Model Saved!\n",
      "Epoch 00083: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.32817424189369\n",
      "Total adversarial train loss: 167.26428523659706\n",
      "\n",
      "[ Test epoch: 84 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.41549691184728\n",
      "Total adversarial test Accuarcy: 34.306569343065696\n",
      "Model Saved!\n",
      "Epoch 00084: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133760> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.18810841095315\n",
      "Total adversarial train loss: 166.46629737317562\n",
      "\n",
      "[ Test epoch: 85 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.12408759124087\n",
      "Total adversarial test Accuarcy: 37.00168444693992\n",
      "Model Saved!\n",
      "Epoch 00085: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133760> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.39120386581693\n",
      "Total adversarial train loss: 165.8582319021225\n",
      "\n",
      "[ Test epoch: 86 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 61.706906232453676\n",
      "Total adversarial test Accuarcy: 35.82257158899495\n",
      "Model Saved!\n",
      "Epoch 00086: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.44870088941802\n",
      "Total adversarial train loss: 163.87282022833824\n",
      "\n",
      "[ Test epoch: 87 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.30320044918585\n",
      "Total adversarial test Accuarcy: 36.60864682762493\n",
      "Model Saved!\n",
      "Epoch 00087: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133BC0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.46824007283423\n",
      "Total adversarial train loss: 164.537299990654\n",
      "\n",
      "[ Test epoch: 88 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.30320044918585\n",
      "Total adversarial test Accuarcy: 36.27175743964065\n",
      "Model Saved!\n",
      "Epoch 00088: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.28062189228937\n",
      "Total adversarial train loss: 164.63056966662407\n",
      "\n",
      "[ Test epoch: 89 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.40482874789444\n",
      "Total adversarial test Accuarcy: 37.3385738349242\n",
      "Model Saved!\n",
      "Epoch 00089: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133AE0> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 66.79039148399748\n",
      "Total adversarial train loss: 164.00206357240677\n",
      "\n",
      "[ Test epoch: 90 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.74171813587872\n",
      "Total adversarial test Accuarcy: 35.93486805165637\n",
      "Model Saved!\n",
      "Epoch 00090: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133760> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.39267455704181\n",
      "Total adversarial train loss: 162.35554759204388\n",
      "\n",
      "[ Test epoch: 91 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.40482874789444\n",
      "Total adversarial test Accuarcy: 35.99101628298708\n",
      "Model Saved!\n",
      "Epoch 00091: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.43469430632398\n",
      "Total adversarial train loss: 161.01713724434376\n",
      "\n",
      "[ Test epoch: 92 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 61.03312745648512\n",
      "Total adversarial test Accuarcy: 35.261089275687816\n",
      "Model Saved!\n",
      "Epoch 00092: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133760> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.4136844316829\n",
      "Total adversarial train loss: 161.74532687664032\n",
      "\n",
      "[ Test epoch: 93 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.06793935991016\n",
      "Total adversarial test Accuarcy: 35.317237507018525\n",
      "Model Saved!\n",
      "Epoch 00093: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133140> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.53974367952938\n",
      "Total adversarial train loss: 162.15012370049953\n",
      "\n",
      "[ Test epoch: 94 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 61.53846153846154\n",
      "Total adversarial test Accuarcy: 33.40819764177429\n",
      "Model Saved!\n",
      "Epoch 00094: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.40668114013586\n",
      "Total adversarial train loss: 159.75850777328014\n",
      "\n",
      "[ Test epoch: 95 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 58.05727119595733\n",
      "Total adversarial test Accuarcy: 38.23694553621561\n",
      "Model Saved!\n",
      "Epoch 00095: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133760> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.700819385111\n",
      "Total adversarial train loss: 160.87530943751335\n",
      "\n",
      "[ Test epoch: 96 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 61.089275687815835\n",
      "Total adversarial test Accuarcy: 35.99101628298708\n",
      "Model Saved!\n",
      "Epoch 00096: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 68.10000700329155\n",
      "Total adversarial train loss: 159.9154079258442\n",
      "\n",
      "[ Test epoch: 97 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 60.02245929253228\n",
      "Total adversarial test Accuarcy: 37.28242560359349\n",
      "Model Saved!\n",
      "Epoch 00097: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 67.97394775544505\n",
      "Total adversarial train loss: 159.7767633497715\n",
      "\n",
      "[ Test epoch: 98 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 59.57327344188658\n",
      "Total adversarial test Accuarcy: 36.552498596294214\n",
      "Model Saved!\n",
      "Epoch 00098: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total adversarial train accuracy: 68.1910497934029\n",
      "Total adversarial train loss: 158.32385815680027\n",
      "\n",
      "[ Test epoch: 99 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign test accuarcy: 58.338012352610896\n",
      "Total adversarial test Accuarcy: 36.83323975294778\n",
      "Model Saved!\n",
      "Epoch 00099: adjusting learning rate of group <generator object Module.parameters at 0x0000021216133680> to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisaimodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
